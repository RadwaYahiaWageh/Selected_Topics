{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgBMm_-0Rfjq",
        "outputId": "08635ce4-fdab-4437-f1a4-ebffd1645d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Load and preprocess the data\n",
        "data_dir = \"/content/drive/MyDrive/training_set\"  # Data directory\n",
        "image_size = (150, 150)  # Image size\n",
        "\n",
        "# Load and label the images\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load images labeled as \"cats\"\n",
        "cats_images = os.listdir(os.path.join(data_dir, \"cats\"))\n",
        "for img_name in cats_images:\n",
        "    img = tf.keras.preprocessing.image.load_img(\n",
        "        os.path.join(data_dir, \"cats\", img_name), target_size=image_size\n",
        "    )\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    images.append(img_array)\n",
        "    labels.append(0)  # Label the image as 0 to represent cats\n",
        "\n",
        "# Load images labeled as \"dogs\"\n",
        "dogs_images = os.listdir(os.path.join(data_dir, \"dogs\"))\n",
        "for img_name in dogs_images:\n",
        "    img = tf.keras.preprocessing.image.load_img(\n",
        "        os.path.join(data_dir, \"dogs\", img_name), target_size=image_size\n",
        "    )\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    images.append(img_array)\n",
        "    labels.append(1)  # Label the image as 1 to represent dogs\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Convert data values to [0, 1] range\n",
        "train_images = train_images.astype(\"float32\") / 255.0\n",
        "test_images = test_images.astype(\"float32\") / 255.0\n",
        "\n",
        "# Step 2: Define the standard deep learning model\n",
        "model_standard = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the standard model\n",
        "model_standard.compile(optimizer='adam',\n",
        "                       loss='binary_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "# Step 3: Train the standard deep learning model\n",
        "history_standard = model_standard.fit(train_images, train_labels, epochs=10,\n",
        "                                      validation_data=(test_images, test_labels))\n",
        "\n",
        "# Step 4: Define the approximate Bayesian deep learning model with Monte Carlo dropout\n",
        "class MC_Dropout(layers.Dropout):\n",
        "    def call(self, inputs):\n",
        "        return super().call(inputs, training=True)\n",
        "\n",
        "model_bayesian = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    MC_Dropout(rate=0.5),  # Monte Carlo dropout layer\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the Bayesian model\n",
        "model_bayesian.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the approximate Bayesian deep learning model with Monte Carlo dropout\n",
        "history_bayesian = model_bayesian.fit(train_images, train_labels, epochs=10,\n",
        "                                      validation_data=(test_images, test_labels))\n",
        "\n",
        "# Step 6: Evaluate both models and calculate standard deviation for the Bayesian model\n",
        "test_loss_standard, test_accuracy_standard = model_standard.evaluate(test_images, test_labels)\n",
        "test_loss_bayesian, test_accuracy_bayesian = model_bayesian.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"Standard Model Test Accuracy:\", test_accuracy_standard)\n",
        "print(\"Bayesian Model Test Accuracy:\", test_accuracy_bayesian)\n",
        "\n",
        "# Monte Carlo dropout for approximate Bayesian inference\n",
        "def mc_dropout_predict(model, X_test, num_samples):\n",
        "    y_preds = np.stack([model.predict(X_test) for _ in range(num_samples)], axis=0)\n",
        "    y_mean = np.mean(y_preds, axis=0)\n",
        "    y_std = np.std(y_preds, axis=0)\n",
        "    return y_mean, y_std\n",
        "\n",
        "num_samples_mc_dropout = 50  # Number of Monte Carlo samples\n",
        "y_mean_mc_dropout, y_std_mc_dropout = mc_dropout_predict(model_bayesian, test_images, num_samples_mc_dropout)\n",
        "\n",
        "# Calculate standard deviation\n",
        "std_dev_mc_dropout = np.mean(y_std_mc_dropout)\n",
        "\n",
        "print(\"Standard Deviation of Bayesian Model (Monte Carlo Dropout):\", std_dev_mc_dropout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3sSsBv9ZmRv",
        "outputId": "47dfbed2-2f0f-4769-b88f-93bcdb4a4a9a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "75/75 [==============================] - 11s 49ms/step - loss: 0.7036 - accuracy: 0.4950 - val_loss: 0.6921 - val_accuracy: 0.4767\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.6901 - accuracy: 0.5204 - val_loss: 0.6884 - val_accuracy: 0.5250\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 2s 28ms/step - loss: 0.6813 - accuracy: 0.5521 - val_loss: 0.6672 - val_accuracy: 0.5917\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 2s 28ms/step - loss: 0.6504 - accuracy: 0.6209 - val_loss: 0.6557 - val_accuracy: 0.6217\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 2s 32ms/step - loss: 0.6164 - accuracy: 0.6651 - val_loss: 0.6527 - val_accuracy: 0.6217\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 2s 29ms/step - loss: 0.5885 - accuracy: 0.6802 - val_loss: 0.6598 - val_accuracy: 0.6350\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.5412 - accuracy: 0.7198 - val_loss: 0.6366 - val_accuracy: 0.6450\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 2s 28ms/step - loss: 0.5080 - accuracy: 0.7477 - val_loss: 0.5903 - val_accuracy: 0.6767\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 2s 28ms/step - loss: 0.4721 - accuracy: 0.7715 - val_loss: 0.5865 - val_accuracy: 0.6867\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.4077 - accuracy: 0.8207 - val_loss: 0.6901 - val_accuracy: 0.6767\n",
            "Epoch 1/10\n",
            "75/75 [==============================] - 6s 31ms/step - loss: 0.7086 - accuracy: 0.4950 - val_loss: 0.6914 - val_accuracy: 0.5467\n",
            "Epoch 2/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.6928 - accuracy: 0.5209 - val_loss: 0.6870 - val_accuracy: 0.5583\n",
            "Epoch 3/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.6793 - accuracy: 0.5663 - val_loss: 0.6839 - val_accuracy: 0.5750\n",
            "Epoch 4/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.6667 - accuracy: 0.6118 - val_loss: 0.6767 - val_accuracy: 0.5500\n",
            "Epoch 5/10\n",
            "75/75 [==============================] - 2s 29ms/step - loss: 0.6402 - accuracy: 0.6330 - val_loss: 0.6450 - val_accuracy: 0.6200\n",
            "Epoch 6/10\n",
            "75/75 [==============================] - 2s 29ms/step - loss: 0.5972 - accuracy: 0.6885 - val_loss: 0.6502 - val_accuracy: 0.6550\n",
            "Epoch 7/10\n",
            "75/75 [==============================] - 2s 27ms/step - loss: 0.5541 - accuracy: 0.7269 - val_loss: 0.6022 - val_accuracy: 0.7033\n",
            "Epoch 8/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.4954 - accuracy: 0.7581 - val_loss: 0.6196 - val_accuracy: 0.6817\n",
            "Epoch 9/10\n",
            "75/75 [==============================] - 2s 26ms/step - loss: 0.4546 - accuracy: 0.7756 - val_loss: 0.5890 - val_accuracy: 0.6883\n",
            "Epoch 10/10\n",
            "75/75 [==============================] - 2s 28ms/step - loss: 0.3670 - accuracy: 0.8386 - val_loss: 0.6034 - val_accuracy: 0.7500\n",
            "19/19 [==============================] - 0s 11ms/step - loss: 0.6901 - accuracy: 0.6767\n",
            "19/19 [==============================] - 0s 10ms/step - loss: 0.6056 - accuracy: 0.7367\n",
            "Standard Model Test Accuracy: 0.6766666769981384\n",
            "Bayesian Model Test Accuracy: 0.7366666793823242\n",
            "19/19 [==============================] - 0s 9ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 9ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 11ms/step\n",
            "19/19 [==============================] - 0s 11ms/step\n",
            "19/19 [==============================] - 0s 12ms/step\n",
            "19/19 [==============================] - 0s 11ms/step\n",
            "19/19 [==============================] - 0s 12ms/step\n",
            "19/19 [==============================] - 0s 9ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 9ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 9ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 11ms/step\n",
            "19/19 [==============================] - 0s 10ms/step\n",
            "19/19 [==============================] - 0s 10ms/step\n",
            "19/19 [==============================] - 0s 12ms/step\n",
            "19/19 [==============================] - 0s 12ms/step\n",
            "19/19 [==============================] - 0s 11ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 9ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "19/19 [==============================] - 0s 8ms/step\n",
            "Standard Deviation of Bayesian Model (Monte Carlo Dropout): 0.054224167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import NewType\n",
        "import keras\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # First, we create a model that maps the input image to the activations\n",
        "    # of the last conv layer as well as the output predictions\n",
        "    grad_model = keras.models.Model(\n",
        "        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    # Then, we compute the gradient of the top predicted class for our input image\n",
        "    # with respect to the activations of the last conv layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # This is the gradient of the output neuron (top predicted or chosen)\n",
        "    # with regard to the output feature map of the last conv layer\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # This is a vector where each entry is the mean intensity of the gradient\n",
        "    # over a specific feature map channel\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # We multiply each channel in the feature map array\n",
        "    # by \"how important this channel is\" with regard to the top predicted class\n",
        "    # then sum all the channels to obtain the heatmap class activation\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "\n",
        "# Prepare image\n",
        "new_images = np.expand_dims(test_images[0], axis=0)\n",
        "img_array = new_images\n",
        "\n",
        "# Make model\n",
        "model = model_standard\n",
        "\n",
        "# Remove last layer's softmax\n",
        "model.layers[-1].activation = None\n",
        "\n",
        "# Print what the top predicted class is\n",
        "preds = test_labels[0]\n",
        "\n",
        "\n",
        "# Generate class activation heatmap\n",
        "heatmap = make_gradcam_heatmap(img_array, model, \"max_pooling2d_3\")\n",
        "\n",
        "# Display heatmap\n",
        "plt.matshow(heatmap)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "Ci3bprE4aOpb",
        "outputId": "8cb92b6a-6196-49f2-bec3-3f90e27e6730"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 480x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAGkCAYAAAAIduO+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAX8UlEQVR4nO3df2zUhf3H8de1R6+ovROQQruWihFFqK1IoemqToVpGiTqH0oIZg0zSyRlgMTE9J+BMeNY8t2C20gFtonJ1oFbUnFmwBhKiZGOUr5NABOkwL5UEKr78r1rqxzQ+3z/+H69rZMin+vn3Q93PB/JZfb2OT6vTzZ5cj9aAo7jOAIAwEiO3wMAANmN0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAExlbWjWr1+v22+/Xfn5+aqurtb+/fv9npS2vXv3av78+SouLlYgENDbb7/t96Rhi0ajmjVrlgoKClRYWKinnnpKR48e9XvWsDQ1NamiokLhcFjhcFg1NTXavn2737M8tXbtWgUCAa1YscLvKcOyevVqBQKBQbepU6f6PWvYTp8+reeee07jxo3T6NGjde+99+rAgQN+z8rO0GzdulUrV67UqlWrdPDgQVVWVurxxx9XT0+P39PS0t/fr8rKSq1fv97vKZ5pbW1VQ0OD2tratGvXLl26dEmPPfaY+vv7/Z6WtpKSEq1du1YdHR06cOCAHn30UT355JM6cuSI39M80d7erg0bNqiiosLvKZ6YPn26Pv3009Ttgw8+8HvSsJw/f161tbUaNWqUtm/fro8++kg//elPNWbMGL+nSU4Wmj17ttPQ0JD6emBgwCkuLnai0aiPq7whyWlpafF7hud6enocSU5ra6vfUzw1ZswY51e/+pXfM4att7fXmTJlirNr1y7nO9/5jrN8+XK/Jw3LqlWrnMrKSr9neOrll192HnjgAb9nXFHWPaO5ePGiOjo6NHfu3NR9OTk5mjt3rvbt2+fjMlxNLBaTJI0dO9bnJd4YGBjQli1b1N/fr5qaGr/nDFtDQ4PmzZs36N+rTHfs2DEVFxfrjjvu0KJFi3Tq1Cm/Jw3LO++8o6qqKj3zzDMqLCzUjBkztGnTJr9nScrCl84+//xzDQwMaMKECYPunzBhgs6ePevTKlxNMpnUihUrVFtbq/Lycr/nDMuhQ4d0yy23KBQK6YUXXlBLS4umTZvm96xh2bJliw4ePKhoNOr3FM9UV1dr8+bN2rFjh5qamnTy5Ek9+OCD6u3t9Xta2k6cOKGmpiZNmTJFO3fu1JIlS7Rs2TK9+eabfk9T0O8BQENDgw4fPpzxr5FL0t13363Ozk7FYjH98Y9/VH19vVpbWzM2Nt3d3Vq+fLl27dql/Px8v+d4pq6uLvXPFRUVqq6uVllZmd566y09//zzPi5LXzKZVFVVldasWSNJmjFjhg4fPqzXX39d9fX1vm7Lumc0t912m3Jzc3Xu3LlB9587d04TJ070aRWGsnTpUr377rt6//33VVJS4vecYcvLy9Odd96pmTNnKhqNqrKyUq+99prfs9LW0dGhnp4e3X///QoGgwoGg2ptbdXPf/5zBYNBDQwM+D3RE7feeqvuuusudXV1+T0lbUVFRV/7A80999xzXbwkmHWhycvL08yZM7V79+7UfclkUrt3786K18qzheM4Wrp0qVpaWvTee+9p8uTJfk8ykUwmlUgk/J6Rtjlz5ujQoUPq7OxM3aqqqrRo0SJ1dnYqNzfX74me6Ovr0/Hjx1VUVOT3lLTV1tZ+7VsEPv74Y5WVlfm06J+y8qWzlStXqr6+XlVVVZo9e7bWrVun/v5+LV682O9paenr6xv0J62TJ0+qs7NTY8eO1aRJk3xclr6GhgY1Nzdr27ZtKigoSL1/FolENHr0aJ/XpaexsVF1dXWaNGmSent71dzcrD179mjnzp1+T0tbQUHB1943u/nmmzVu3LiMfj/tpZde0vz581VWVqYzZ85o1apVys3N1cKFC/2elrYXX3xR3/72t7VmzRo9++yz2r9/vzZu3KiNGzf6PS07P97sOI7zi1/8wpk0aZKTl5fnzJ4922lra/N7Utref/99R9LXbvX19X5PS9uVrkeS88Ybb/g9LW3f//73nbKyMicvL88ZP368M2fOHOcvf/mL37M8lw0fb16wYIFTVFTk5OXlOd/61recBQsWOF1dXX7PGrY//elPTnl5uRMKhZypU6c6Gzdu9HuS4ziOE3Acx/GpcQCAG0DWvUcDALi+EBoAgClCAwAwRWgAAKYIDQDAFKEBAJjK2tAkEgmtXr06o78r+99xTZkjG6+La8oM1+M1Ze330cTjcUUiEcViMYXDYb/neIJryhzZeF1cU2a4Hq8pa5/RAACuD4QGAGBqxH+oZjKZ1JkzZ1RQUKBAIGB2nng8Pug/swHXlDmy8bq4pswwktfkOI56e3tVXFysnJyhn7eM+Hs0n3zyiUpLS0fylAAAQ93d3Vf9+6RG/BlNQUGBJOmh0NMKBkaN9OnNJC9cP5/wALJBzk2Z+ddFXE3yiy/9nuCpy7qkD/Tn1O/rQxnx0Hz1clkwMErBQN5In95MMpD0ewKQVXKy6PeHryQDl/2e4K3/fz3sm94G4cMAAABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAqbRCs379et1+++3Kz89XdXW19u/f7/UuAECWcB2arVu3auXKlVq1apUOHjyoyspKPf744+rp6bHYBwDIcK5D87Of/Uw/+MEPtHjxYk2bNk2vv/66brrpJv3mN7+x2AcAyHCuQnPx4kV1dHRo7ty5//wFcnI0d+5c7du374qPSSQSisfjg24AgBuHq9B8/vnnGhgY0IQJEwbdP2HCBJ09e/aKj4lGo4pEIqlbaWlp+msBABnH/FNnjY2NisViqVt3d7f1KQEA15Ggm4Nvu+025ebm6ty5c4PuP3funCZOnHjFx4RCIYVCofQXAgAymqtnNHl5eZo5c6Z2796dui+ZTGr37t2qqanxfBwAIPO5ekYjSStXrlR9fb2qqqo0e/ZsrVu3Tv39/Vq8eLHFPgBAhnMdmgULFuizzz7Tj370I509e1b33XefduzY8bUPCAAAIEkBx3GckTxhPB5XJBLRo/nPKhjIG8lTm0peuOD3BCCr5Nx0k98TPJf84gu/J3jqsnNJe7RNsVhM4XB4yOP4WWcAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATAX9OnHXKxXKyc/36/SeO/7s635P8FzbhQG/J3ju1dp5fk/wXn7I7wUmLp/8L78neC75wH1+T/BU8vIFad+2bzyOZzQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmXIdm7969mj9/voqLixUIBPT2228bzAIAZAvXoenv71dlZaXWr19vsQcAkGWCbh9QV1enuro6iy0AgCzkOjRuJRIJJRKJ1NfxeNz6lACA64j5hwGi0agikUjqVlpaan1KAMB1xDw0jY2NisViqVt3d7f1KQEA1xHzl85CoZBCoZD1aQAA1ym+jwYAYMr1M5q+vj51dXWlvj558qQ6Ozs1duxYTZo0ydNxAIDM5zo0Bw4c0COPPJL6euXKlZKk+vp6bd682bNhAIDs4Do0Dz/8sBzHsdgCAMhCvEcDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwFTQrxPf8XK7goFRfp3ec/P+Y57fEzz3RXmx3xM8l/fbT/2e4Ln//jLk9wQT/3Okxu8Jngsk/V7greSFgLTvm4/jGQ0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApV6GJRqOaNWuWCgoKVFhYqKeeekpHjx612gYAyAKuQtPa2qqGhga1tbVp165dunTpkh577DH19/db7QMAZLigm4N37Ngx6OvNmzersLBQHR0deuihhzwdBgDIDq5C8+9isZgkaezYsUMek0gklEgkUl/H4/HhnBIAkGHS/jBAMpnUihUrVFtbq/Ly8iGPi0ajikQiqVtpaWm6pwQAZKC0Q9PQ0KDDhw9ry5YtVz2usbFRsVgsdevu7k73lACADJTWS2dLly7Vu+++q71796qkpOSqx4ZCIYVCobTGAQAyn6vQOI6jH/7wh2ppadGePXs0efJkq10AgCzhKjQNDQ1qbm7Wtm3bVFBQoLNnz0qSIpGIRo8ebTIQAJDZXL1H09TUpFgspocfflhFRUWp29atW632AQAynOuXzgAAcIOfdQYAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAVNDvAdni8ien/Z7guVDRWL8neK7rP0v8nuC5iW2O3xNMFAaSfk/wXOj8Zb8neOry5Ys6eQ3H8YwGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAlKvQNDU1qaKiQuFwWOFwWDU1Ndq+fbvVNgBAFnAVmpKSEq1du1YdHR06cOCAHn30UT355JM6cuSI1T4AQIYLujl4/vz5g77+8Y9/rKamJrW1tWn69OmeDgMAZAdXoflXAwMD+sMf/qD+/n7V1NQMeVwikVAikUh9HY/H0z0lACADuf4wwKFDh3TLLbcoFArphRdeUEtLi6ZNmzbk8dFoVJFIJHUrLS0d1mAAQGZxHZq7775bnZ2d+tvf/qYlS5aovr5eH3300ZDHNzY2KhaLpW7d3d3DGgwAyCyuXzrLy8vTnXfeKUmaOXOm2tvb9dprr2nDhg1XPD4UCikUCg1vJQAgYw37+2iSyeSg92AAAPhXrp7RNDY2qq6uTpMmTVJvb6+am5u1Z88e7dy502ofACDDuQpNT0+Pvve97+nTTz9VJBJRRUWFdu7cqe9+97tW+wAAGc5VaH79619b7QAAZCl+1hkAwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU0G/Thy4/x4FcvP9Or3nPptZ4PcEz4098qXfEzwX7gr4PcFzpx8b8HuCiXH7ffvtyUz4WHb9O5U7kLim43hGAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYGpYoVm7dq0CgYBWrFjh0RwAQLZJOzTt7e3asGGDKioqvNwDAMgyaYWmr69PixYt0qZNmzRmzBivNwEAskhaoWloaNC8efM0d+7cbzw2kUgoHo8PugEAbhxBtw/YsmWLDh48qPb29ms6PhqN6pVXXnE9DACQHVw9o+nu7tby5cv1u9/9Tvn5+df0mMbGRsVisdStu7s7raEAgMzk6hlNR0eHenp6dP/996fuGxgY0N69e/XLX/5SiURCubm5gx4TCoUUCoW8WQsAyDiuQjNnzhwdOnRo0H2LFy/W1KlT9fLLL38tMgAAuApNQUGBysvLB9138803a9y4cV+7HwAAiZ8MAAAw5vpTZ/9uz549HswAAGQrntEAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmgn6d+PzUAuXm5ft1es+NP9jn9wTPBT464fcEzxX23+73BM9NfO+C3xNMDHx83O8Jnkv6PcBjSefSNR3HMxoAgClCAwAwRWgAAKYIDQDAFKEBAJgiNAAAU4QGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABTrkKzevVqBQKBQbepU6dabQMAZIGg2wdMnz5df/3rX//5CwRd/xIAgBuI60oEg0FNnDjxmo9PJBJKJBKpr+PxuNtTAgAymOv3aI4dO6bi4mLdcccdWrRokU6dOnXV46PRqCKRSOpWWlqa9lgAQOZxFZrq6mpt3rxZO3bsUFNTk06ePKkHH3xQvb29Qz6msbFRsVgsdevu7h72aABA5nD10lldXV3qnysqKlRdXa2ysjK99dZbev7556/4mFAopFAoNLyVAICMNayPN996662666671NXV5dUeAECWGVZo+vr6dPz4cRUVFXm1BwCQZVyF5qWXXlJra6v+/ve/68MPP9TTTz+t3NxcLVy40GofACDDuXqP5pNPPtHChQv1j3/8Q+PHj9cDDzygtrY2jR8/3mofACDDuQrNli1brHYAALIUP+sMAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgKmgXye+tXm/goFRfp3ec47fAwzkFk30e4LnnL4v/Z7guYFjJ/yeYCInP9/vCZ5LXrjg9wRf8IwGAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgClCAwAwRWgAAKYIDQDAlOvQnD59Ws8995zGjRun0aNH695779WBAwcstgEAskDQzcHnz59XbW2tHnnkEW3fvl3jx4/XsWPHNGbMGKt9AIAM5yo0P/nJT1RaWqo33ngjdd/kyZM9HwUAyB6uXjp75513VFVVpWeeeUaFhYWaMWOGNm3adNXHJBIJxePxQTcAwI3DVWhOnDihpqYmTZkyRTt37tSSJUu0bNkyvfnmm0M+JhqNKhKJpG6lpaXDHg0AyBwBx3Gcaz04Ly9PVVVV+vDDD1P3LVu2TO3t7dq3b98VH5NIJJRIJFJfx+NxlZaW6mE9qWBg1DCmw1qwaKLfEzzn3HKT3xM8N3DshN8TTOTk5/s9wXPJCxf8nuCpy84l7dE2xWIxhcPhIY9z9YymqKhI06ZNG3TfPffco1OnTg35mFAopHA4POgGALhxuApNbW2tjh49Oui+jz/+WGVlZZ6OAgBkD1ehefHFF9XW1qY1a9aoq6tLzc3N2rhxoxoaGqz2AQAynKvQzJo1Sy0tLfr973+v8vJyvfrqq1q3bp0WLVpktQ8AkOFcfR+NJD3xxBN64oknLLYAALIQP+sMAGCK0AAATBEaAIApQgMAMEVoAACmCA0AwBShAQCYIjQAAFOEBgBgitAAAEwRGgCAKUIDADBFaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMuf6rnIfLcRxJ0mVdkpyRPjtcSV70e4HnnIFcvyd4bsC55PcEEzlO9v05OJll/1td1v9dz1e/rw9lxEPT29srSfpAfx7pU8Ots34PwA3tgt8DcK16e3sViUSG/O8DzjelyGPJZFJnzpxRQUGBAoGA2Xni8bhKS0vV3d2tcDhsdp6RxDVljmy8Lq4pM4zkNTmOo97eXhUXFysnZ+hnoCP+jCYnJ0clJSUjdr5wOJw1/wf6CteUObLxurimzDBS13S1ZzJfyb4XQQEA1xVCAwAwlbWhCYVCWrVqlUKhkN9TPMM1ZY5svC6uKTNcj9c04h8GAADcWLL2GQ0A4PpAaAAApggNAMAUoQEAmCI0AABThAYAYIrQAABMERoAgKn/BQLg8EV3NoR4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}